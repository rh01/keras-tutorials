{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "#categorical_crossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# load mnist data\n",
    "def load_mnist_data(number):\n",
    "        # the data, shuffled and split between train and test sets\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "        x_train = x_train[0:number]\n",
    "        y_train = y_train[0:number]\n",
    "        # x_train = np.reshape(x_train, (len(x_train),  28, 28, 1))\n",
    "        x_train = np.reshape(x_train, (number,  28, 28, 1))\n",
    "        x_test = np.reshape(x_test, (10000,  28, 28, 1))\n",
    "        # x_train = x_train.reshape(number, 784)\n",
    "        # x_test = x_test.reshape(10000, 784)\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        # convert class vectors to binary class matrices\n",
    "        y_train = np_utils.to_categorical(y_train, 10)\n",
    "        y_test = np_utils.to_categorical(y_test, 10)\n",
    "        x_train = x_train/255\n",
    "        x_test = x_test/255\n",
    "        return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_mnist_data(10000)\n",
    "# print x_train.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ(['backend']) = 'tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_10 (Dense)                 (None, 500)           392500      dense_input_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 500)           0           dense_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 500)           250500      activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 500)           0           dense_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 500)           250500      activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 500)           0           dense_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 10)            5010        activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 10)            0           dense_13[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 898510\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.4569 - acc: 0.8617     \n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.1611 - acc: 0.9524     \n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.0861 - acc: 0.9740     \n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.0637 - acc: 0.9805     \n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.0362 - acc: 0.9897     \n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.0311 - acc: 0.9892     \n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.0284 - acc: 0.9909     \n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.0324 - acc: 0.9892     \n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.0193 - acc: 0.9932     \n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.0218 - acc: 0.9930     \n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.0132 - acc: 0.9961     \n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.0093 - acc: 0.9973     \n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.0065 - acc: 0.9980     \n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.0048 - acc: 0.9985     \n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.0070 - acc: 0.9974     \n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.0215 - acc: 0.9926     \n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.0180 - acc: 0.9947     \n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.0240 - acc: 0.9927     \n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.0307 - acc: 0.9910     \n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 4s - loss: 0.0140 - acc: 0.9957     \n",
      " 9984/10000 [============================>.] - ETA: 0s('\\nTrain Acc:', 0.99839999999999995)\n",
      " 9952/10000 [============================>.] - ETA: 0s('\\nTest Acc:', 0.95840000000000003)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=28*28,output_dim=500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(output_dim=500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(output_dim=500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(output_dim=10))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,y_train,nb_epoch=20,batch_size=100)\n",
    "\n",
    "result_train = model.evaluate(x_train,y_train)\n",
    "print('\\nTrain Acc:',result_train[1])\n",
    "result_test = model.evaluate(x_test,y_test)\n",
    "print('\\nTest Acc:',result_test[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_20 (Convolution2D) (None, 26, 26, 25)    250         convolution2d_input_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_19 (MaxPooling2D)   (None, 13, 13, 25)    0           convolution2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_21 (Convolution2D) (None, 11, 11, 50)    11300       maxpooling2d_19[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_20 (MaxPooling2D)   (None, 5, 5, 50)      0           convolution2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)             (None, 1250)          0           maxpooling2d_20[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_22 (Dense)                 (None, 10)            12510       flatten_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_23 (Dense)                 (None, 10)            110         dense_22[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 24170\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 9s - loss: 1.4267 - acc: 0.5435     \n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 9s - loss: 0.5499 - acc: 0.8367     \n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 8s - loss: 0.2685 - acc: 0.9271     \n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 8s - loss: 0.1966 - acc: 0.9433     \n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 9s - loss: 0.1552 - acc: 0.9547     \n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 8s - loss: 0.1320 - acc: 0.9604     \n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 9s - loss: 0.1167 - acc: 0.9642     \n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 9s - loss: 0.0963 - acc: 0.9726     \n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 9s - loss: 0.0911 - acc: 0.9736     \n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 9s - loss: 0.0793 - acc: 0.9758     \n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 9s - loss: 0.0729 - acc: 0.9786     \n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 9s - loss: 0.0627 - acc: 0.9808     \n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 9s - loss: 0.0592 - acc: 0.9821     \n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 9s - loss: 0.0532 - acc: 0.9847     \n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 9s - loss: 0.0499 - acc: 0.9852     \n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 10s - loss: 0.0473 - acc: 0.9847    \n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 9s - loss: 0.0391 - acc: 0.9881     \n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 9s - loss: 0.0398 - acc: 0.9872     \n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 9s - loss: 0.0335 - acc: 0.9905     \n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 8s - loss: 0.0273 - acc: 0.9912     \n",
      "10000/10000 [==============================] - 5s     \n",
      "\n",
      "Train CNN Acc: 0.9936\n",
      " 9984/10000 [============================>.] - ETA: 0s\n",
      "Test CNN Acc: 0.9732\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model2 = Sequential()\n",
    "# For an explanation on conv layers see http://cs231n.github.io/convolutional-networks/#conv\n",
    "# By default the stride/subsample is 1\n",
    "# border_mode \"valid\" means no zero-padding.\n",
    "# If you want zero-padding add a ZeroPadding layer or, if stride is 1 use border_mode=\"same\"\n",
    "# under tf env. input_shape=(raw_row, raw_col, n_channel)\n",
    "model2.add(Conv2D(25,3,3,activation='relu',input_shape=(28,28,1)))\n",
    "model2.add(MaxPooling2D((2,2)))\n",
    "model2.add(Conv2D(50,3,3,activation='relu'))\n",
    "model2.add(MaxPooling2D((2,2)))\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(Dense(output_dim=10, activation='relu'))\n",
    "# model2.add(Activation('relu'))\n",
    "# Adding droput\n",
    "# model2.add(Dropout(0.25))\n",
    "\n",
    "model2.add(Dense(output_dim=10,activation='softmax'))\n",
    "# model2.add(Activation('softmax'))\n",
    "model2.summary()\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model2.fit(x_train,y_train,nb_epoch=20,batch_size=100)\n",
    "\n",
    "result_train = model2.evaluate(x_train,y_train)\n",
    "print '\\nTrain CNN Acc:',result_train[1]\n",
    "result_test = model2.evaluate(x_test,y_test)\n",
    "print '\\nTest CNN Acc:',result_test[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#keras\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense,Flatten,Dropout\n",
    "from scipy.misc import toimage\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(train_x, train_labels), (test_x, test_labels) = mnist.load_data()\n",
    "print train_labels.shape\n",
    "train_x = np.reshape(train_x, (len(train_x), 28, 28, 1))\n",
    "test_x = np.reshape(test_x, (len(test_x), 28, 28, 1))\n",
    "\n",
    "rows,cols=train_x.shape[1:3]\n",
    "classes_out=10\n",
    "x_ip_shape=(rows,cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_28 (Convolution2D) (None, 24, 24, 32)    832         convolution2d_input_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_27 (MaxPooling2D)   (None, 12, 12, 32)    0           convolution2d_28[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_29 (Convolution2D) (None, 6, 6, 64)      100416      maxpooling2d_27[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_28 (MaxPooling2D)   (None, 3, 3, 64)      0           convolution2d_29[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)             (None, 576)           0           maxpooling2d_28[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_30 (Dense)                 (None, 10)            5770        flatten_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 10)            0           dense_30[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_31 (Dense)                 (None, 10)            110         dropout_12[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 107128\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "# 1st conv layer\n",
    "model.add(Conv2D(32, 5, 5, activation='relu', input_shape=x_ip_shape))\n",
    "# 1st max pool\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# 2nd conv layer\n",
    "model.add(Conv2D(64, 7, 7, activation='relu'))\n",
    "# 2nd max pool\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Flattenning the input\n",
    "model.add(Flatten())\n",
    "# 1st Fully connected layer\n",
    "model.add(Dense(10, activation='relu'))\n",
    "# Adding droput\n",
    "model.add(Dropout(0.25))\n",
    "# softmax layer\n",
    "model.add(Dense(classes_out, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Error when checking model target: expected dense_29 to have shape (None, 10) but got array with shape (60000, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-d668e9a1c97a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# scores = model.evaluate(test_x, test_labels, verbose=0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# print(\"Accuracy: %.2f%%\" % (scores[1]*100))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hadoop/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    625\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/home/hadoop/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                                                            \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m                                                            \u001b[0mcheck_batch_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m                                                            batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1053\u001b[0m         \u001b[1;31m# prepare validation data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hadoop/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size)\u001b[0m\n\u001b[0;32m    981\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m                                    \u001b[0mcheck_batch_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 983\u001b[1;33m                                    exception_prefix='model target')\n\u001b[0m\u001b[0;32m    984\u001b[0m         sample_weights = standardize_sample_weights(sample_weight,\n\u001b[0;32m    985\u001b[0m                                                     self.output_names)\n",
      "\u001b[1;32m/home/hadoop/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_dim, exception_prefix)\u001b[0m\n\u001b[0;32m    109\u001b[0m                                         \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                                         \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m                                         str(array.shape))\n\u001b[0m\u001b[0;32m    112\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Error when checking model target: expected dense_29 to have shape (None, 10) but got array with shape (60000, 1)"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs=20000\n",
    "batch_size=50\n",
    "model.fit(train_x, train_labels, nb_epoch=epochs, batch_size=batch_size)\n",
    "# scores = model.evaluate(test_x, test_labels, verbose=0)\n",
    "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
